{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2c2d38f",
   "metadata": {},
   "source": [
    "# Customer Behavior Predictive Analysis\n",
    "## IIMK's Professional Certificate in Data Science and Artificial Intelligence for Managers\n",
    "**Student Name**: Lalit Nayyar  \n",
    "**Email ID**: lalitnayyar@gmail.com  \n",
    "**Assignment**: Week 4: Required Assignment 4.1\n",
    "\n",
    "This notebook focuses on predictive analytics for customer behavior, including:\n",
    "1. Feature Engineering\n",
    "2. Model Development\n",
    "3. Prediction and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087dd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "print(\"All required libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d84fa",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Validation\n",
    "Loading the cleaned customer data from previous analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc0ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(df):\n",
    "    '''Validate the loaded data for required columns and data quality'''\n",
    "    required_columns = ['CustomerID', 'InvoiceNo', 'InvoiceDate', \n",
    "                       'Quantity', 'UnitPrice', 'TotalAmount']\n",
    "    \n",
    "    # Check required columns\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Check data types\n",
    "    if not pd.api.types.is_numeric_dtype(df['CustomerID']):\n",
    "        raise ValueError(\"CustomerID should be numeric\")\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['InvoiceDate']):\n",
    "        raise ValueError(\"InvoiceDate should be datetime\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Load and validate data\n",
    "try:\n",
    "    df = pd.read_csv('cleaned_retail_data.csv')\n",
    "    if 'InvoiceDate' in df.columns:\n",
    "        df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "    \n",
    "    validate_data(df)\n",
    "    print(\"Data loaded and validated successfully!\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(\"\n",
    "Sample of the data:\")\n",
    "    display(df.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: cleaned_retail_data.csv not found!\")\n",
    "    print(\"Please run the analysis notebook first to generate the cleaned dataset.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in data loading/validation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e0d674",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "Creating customer-level features for predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_customer_features(df):\n",
    "    '''Create comprehensive customer-level features for prediction'''\n",
    "    try:\n",
    "        # Calculate recency\n",
    "        max_date = df['InvoiceDate'].max()\n",
    "        customer_features = df.groupby('CustomerID').agg({\n",
    "            'InvoiceDate': lambda x: (max_date - x.max()).days,  # Recency\n",
    "            'InvoiceNo': 'count',  # Frequency\n",
    "            'TotalAmount': ['sum', 'mean', 'std'],  # Monetary metrics\n",
    "            'Quantity': ['sum', 'mean', 'std'],  # Purchase quantity metrics\n",
    "        })\n",
    "        \n",
    "        # Flatten column names\n",
    "        customer_features.columns = [\n",
    "            'Recency', 'Frequency', \n",
    "            'TotalRevenue', 'AvgPurchaseValue', 'StdPurchaseValue',\n",
    "            'TotalQuantity', 'AvgQuantity', 'StdQuantity'\n",
    "        ]\n",
    "        \n",
    "        # Add derived features\n",
    "        customer_features['PurchaseVariability'] = customer_features['StdPurchaseValue'] / customer_features['AvgPurchaseValue']\n",
    "        customer_features['QuantityVariability'] = customer_features['StdQuantity'] / customer_features['AvgQuantity']\n",
    "        \n",
    "        # Handle infinities and NaNs\n",
    "        customer_features = customer_features.replace([np.inf, -np.inf], np.nan)\n",
    "        customer_features = customer_features.fillna(0)\n",
    "        \n",
    "        print(\"Feature engineering completed successfully!\")\n",
    "        return customer_features\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in feature engineering: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create features\n",
    "customer_features = create_customer_features(df)\n",
    "if customer_features is not None:\n",
    "    print(\"\n",
    "Feature summary:\")\n",
    "    display(customer_features.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e127d57",
   "metadata": {},
   "source": [
    "## 3. Model Preparation\n",
    "Preparing features and target variable for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a80b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_and_target(customer_features):\n",
    "    '''Prepare features and target for modeling'''\n",
    "    try:\n",
    "        # Use TotalRevenue as target variable\n",
    "        X = customer_features.drop('TotalRevenue', axis=1)\n",
    "        y = customer_features['TotalRevenue']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        print(\"Data preparation completed successfully!\")\n",
    "        return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in data preparation: {e}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "# Prepare data for modeling\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, scaler = prepare_features_and_target(customer_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d6536",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation\n",
    "Training Random Forest model and evaluating its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21d77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    '''Train and evaluate the Random Forest model'''\n",
    "    try:\n",
    "        # Train model\n",
    "        rf_model = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            random_state=42\n",
    "        )\n",
    "        rf_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = rf_model.predict(X_test_scaled)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        print(\"Model Training Results:\")\n",
    "        print(f\"RÂ² Score: {r2:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.2f}\")\n",
    "        print(f\"MAE: {mae:.2f}\")\n",
    "        \n",
    "        # Feature importance\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'importance': rf_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "        plt.title('Feature Importance')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return rf_model, feature_importance\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in model training: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Train and evaluate model\n",
    "if all(v is not None for v in [X_train_scaled, X_test_scaled, y_train, y_test]):\n",
    "    rf_model, feature_importance = train_and_evaluate_model(\n",
    "        X_train_scaled, X_test_scaled, y_train, y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb6de8",
   "metadata": {},
   "source": [
    "## 5. Making Predictions\n",
    "Using the trained model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19996d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, scaler, customer_features, top_n=10):\n",
    "    '''Make predictions for customer revenue'''\n",
    "    try:\n",
    "        if model is None or scaler is None:\n",
    "            raise ValueError(\"Model or scaler not available\")\n",
    "        \n",
    "        # Prepare features for prediction\n",
    "        X_pred = customer_features.drop('TotalRevenue', axis=1)\n",
    "        X_pred_scaled = scaler.transform(X_pred)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_pred_scaled)\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results = pd.DataFrame({\n",
    "            'CustomerID': customer_features.index,\n",
    "            'Actual_Revenue': customer_features['TotalRevenue'],\n",
    "            'Predicted_Revenue': predictions\n",
    "        })\n",
    "        \n",
    "        # Calculate prediction error\n",
    "        results['Prediction_Error'] = abs(results['Actual_Revenue'] - results['Predicted_Revenue'])\n",
    "        results['Error_Percentage'] = (results['Prediction_Error'] / results['Actual_Revenue']) * 100\n",
    "        \n",
    "        print(\"Top 10 Customers by Predicted Revenue:\")\n",
    "        display(results.nlargest(top_n, 'Predicted_Revenue'))\n",
    "        \n",
    "        # Plot actual vs predicted\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(results['Actual_Revenue'], results['Predicted_Revenue'], alpha=0.5)\n",
    "        plt.plot([0, results['Actual_Revenue'].max()], [0, results['Actual_Revenue'].max()], 'r--')\n",
    "        plt.xlabel('Actual Revenue')\n",
    "        plt.ylabel('Predicted Revenue')\n",
    "        plt.title('Actual vs Predicted Revenue')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in making predictions: {e}\")\n",
    "        return None\n",
    "\n",
    "# Make predictions\n",
    "if rf_model is not None and scaler is not None:\n",
    "    prediction_results = make_predictions(rf_model, scaler, customer_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
